[
["index.html", "Building Web Applications with Shiny and SQL Server Preface", " Building Web Applications with Shiny and SQL Server Matthew Sharkey 03.27.2019 Preface This book supplments my presentation at the Omaha R User Group on Thursday, April 4, 2019. "],
["intended-audience.html", "Intended Audience", " Intended Audience If you develop Shiny Applications and your backend is a relational database then this book is for you. The demos and code snippets are written in T-SQL, Microsoft SQL Server dialext of SQL, but the core concepts are applicable accross all RDBMS systems. Data Scientists using R are the primary audience. Database Developers, BI developers, software engineers, data analysts and managers wanting to learn more about Shiny Database applications will also benefit from the material. The reader should have some experiance writing R code or programming. Any knowledge of SQL and relational databases will help but is not required. "],
["software-information.html", "Software information", " Software information My IDEs were Rstudio and SQL Server Management Studio. I used R on windows and SQL Server to build the demo application. R version 3.5.3 (2019-03-11) – “Great Truth” Copyright (C) 2019 The R Foundation for Statistical Computing Platform: x86_64-w64-mingw32/x64 (64-bit) Microsoft SQL Server 2019 (CTP2.3) - 15.0.1300.359 (X64) Feb 15 2019 23:50:43 Copyright (C) 2019 Microsoft Corporation Developer Edition (64-bit) on Windows 10 Home 10.0 (Build 17134: ) Matt Sharkey Omaha, Nebraska "],
["intro.html", "Chapter 1 Use Cases for a Relational Database", " Chapter 1 Use Cases for a Relational Database Relational database management systems (RDBMS) provide a cornerstone for many apps and services. By technology standards, RDBMS are ancient. Strong theoretical underpinnings have kept RDBMS technologies relevant in a volatile industry. Even non-relational data stores have had to add RDBMS-like features. For example, Hadoop has a SQL interface. Even though RDBMS are popular and versatile, they don’t solve every problem. If all I need is a place to store data, then I don’t need a database. Dumping data to a relational database might be tempting, but it will lead to just that- a dump. Codd, the founder of the relational model, once remarked on choosing the right tools: IT should never forget that technology is a means to an end, and not an end in itself. Technologies must be evaluated individually in terms of their ability to satisfy the needs of their respective users. IT should never be reluctant to use the most appropriate interface to satisfy users’ requirements. Attempting to force one technology or tool to satisfy a particular need for which another tool is more effective and efficient is like attempting to drive a screw into a wall with a hammer when a screwdriver is at hand: the screw may eventually enter the wall but at what cost? (E.F. Codd, et al. 1998) So when are RDBMS the best tool for the job? It depends. Here are some questions a developer should ask before deciding to use an RDBMS on a project: Will the data grow? Growing fixed format data is a good candidate for RDBMS. An ETL developer can build a pipeline to update the database as new data becomes available. Will data change? RDBMS excel at tracking historical changes. Developers can use temporal tables or slowly changing dimensions for value level changes. I’ve written in more detail about tracking historical changes here. Is the data bigger than what we can fit into memory? A 20 GB relational table is more accessible than a 20 GB flat file. Does the app need fast data processing? RDBMS can be faster at data processing than other system depending on the workload. Workloads sent to the database can use indexes and automatic parallelization for speed. Does my organizations have the proper infrastructure and skillets? Databases, especially on-premises deployments, need planning and maintenance. The degree of planning depends on the application workload requirements and existing infrastructure. A small commodity server can handle a database workload of 100 batches/sec under load. It’s another story if the app is pushing 10K batches/sec under load. Database maintenance is another consideration. Are you performing back-ups, corruption checking, patching, index de-fragmentation, statistics updates? Cloud databases offload some of the infrastructure duties like backups and patching, but they are not maintenance free. Is the data sensitive? Database products offer a plethora of encryption, auditing, and alerting features. SQL Server, for example, offers data encryption, auditing, and alerting out of the box. It’s possible to recreate a lot of these features without a database but as Codd put it, “at what cost?” Do I need transactions? A balance transfer of $100 from my savings to checking account is an atomic transaction made up of two database queries. One query debits $100 from the savings ledger and one query credits $100 to the checking ledger. These two queries are indivisible. If one query fails, then the entire transaction fails. If a system failure occurred between queries, then I would not want the $100 debit to succeed and the $100 credit to fail. Otherwise, I’d lose $100! How much flexibility do I need? Updating a relational schema is slow and cumbersome. If a project is in the exploratory phase, then a database will add unnecessary complexity. User requirements should drive the data model. The data model drives implementation details. Importing data into a database should not be the end but the means to some end. References "],
["building-and-managing-connections.html", "Chapter 2 Building and Managing Connections ", " Chapter 2 Building and Managing Connections "],
["making-a-connection.html", "2.1 Making a connection", " 2.1 Making a connection R users can integrate SQL Server databases using the DBI and ODBC packages. The first step is to build a connection string. A connection string contains a set of key-value pairs. It tells R where the server is and what user credential to use. Different driver types need different connection string formats. Here are two common connection string configurations. library(DBI) myDriver &lt;- &#39;SQL Server&#39; # Use . for a local connection, otherwise specify Server Machine Name or IP address myServer &lt;- &#39;.&#39; myDatabase &lt;- &#39;Cab_Demo&#39; trusted_connection &lt;- dbConnect(odbc::odbc(),Driver= myDriver,Server = myServer ,Database = myDatabase,Trusted_Connection=&#39;yes&#39;) myUserid &lt;- &#39;Cab_App&#39; myPassword &lt;- Sys.getenv(&#39;Cab_App_Password&#39;) connection &lt;- dbConnect(odbc::odbc(),Driver= myDriver,Server = myServer ,Database = myDatabase,Uid = myUserid,Pwd = myPassword) The trusted_connection uses my windows account instead of a username and password. I prefer windows logins over creating a SQL login because they are easier to manage. My AD system administrator takes care of securing windows credentials. If I use a SQL login, then I’m responsible for guarding and storing the credentials. The second connection string shows how to connect with a SQL login. I use SQL logins for non-windows clients or when connecting to a DB outside the domain. It’s good practice to avoid storing clear text passwords in the client code. So, I stored an environmental variable and accessed it with the Sys.getenv function. "],
["common-connection-problems.html", "2.2 Common Connection Problems", " 2.2 Common Connection Problems I’ve encountered a wide variety of errors when attempting the initial connection. They usually stem from one or more of the following: I didn’t build a valid connection string. ConnectionStrings.com provides a reference for connection string formats. I misspelled something. I need to correct server and database names more than I’d like to admit. I don’t have permissions to the SQL Server. When I see errors like the “The server principal is not able to access.” then I suspect permissions are the issue. If I don’t own the server, then I submit a ticket to the help desk for authorization. If I own the server, then I check the SQL server logs through SQL Server Management Studio. The logs usually direct me to either create a user or grant permissions. I don’t have the right driver selected. It’s easy to attempt a connection with a driver that doesn’t exist on the client. Windows users can check available drivers by searching Administrative tools -&gt; Double click Data Sources. If I publish to an external source, e.g. ShinyApps.IO, then I check their support docs for available driver names. At the time of this blog post, they have SQL Server driver named “SQLServer” available. I need to specify the port number. Sometimes the default port is changed from 1433. In that case, I must specify the port number after the server name, e.g. myServer = ‘.,2050’ A firewall is blocking the connection. One of my previous blog posts shows how to configure a firewall SQL Server access. "],
["executing-a-query.html", "2.3 Executing a Query", " 2.3 Executing a Query Now that I’ve made a connection I’ll verify it with a simple GetDate() query. dbGetQuery(trusted_connection,&quot;Select GetDate()&quot;) dbDisconnect(trusted_connection) I closed the connection by passing the connection variable to the dbDisconnect function. Generally, it is a good idea to close connections after use. Leaving connections open wastes memory and blocks resources for other query sessions. Too many open connections can overload the server and prevent new connections. I’ll show what open connections look like on the back-end. First, I’ll make five connections using a for loop without invoking dbDisconnect. for (i in 1:5) { trusted_connection &lt;- dbConnect(odbc::odbc(),Driver= myDriver,Server = myServer ,Database = myDatabase,Trusted_Connection=&#39;yes&#39;) date &lt;- dbGetQuery(trusted_connection,paste(&quot;Select GetDate() as mydate ,\\&#39;leakedquery\\&#39; as c1,&quot;,i)) } Here’s a query that a system admin might use to watch database connections. It returns information about the five open connections. I’ve used this query to look for applications that might be leaking connections. If I a lot of sleeping connections then I contacted the app developer for a patch. SELECT DB_NAME(p.dbid) as DBName, program_name as Program,CPU,memusage,status,SPID,nt_username FROM sys.sysprocesses p Cross apply sys.dm_exec_sql_text(p.sql_handle) d WHERE program_name = &#39;Rstudio&#39; and text like &#39;%leakedquery%&#39; and text not like &#39;%DB_NAME%&#39; I didn’t issue a dbDisconnect, so the connections stays open until the client closes or R runs garbage collection. "],
["the-pool-package.html", "2.4 The pool Package", " 2.4 The pool Package The pool package opens and closes connections automatically. R users establish a connection to a pool. From then on pool gives the query an idle connection or opens a new connection. Besides simplifying client code, pooled connections can also provide a performance boost. To illustrate, I wrote a sample workload consisting of three queries. Next, I wrote a function to execute the queries using dbConnect/dbDisconnect, and a function to execute the queries using a pool. library(pool) queries &lt;- c(&quot;SELECT Carrier,count(1) FROM [Cab_Demo].[dbo].[flights] group by Carrier&quot;,&quot; Select Avg(distance) From [Cab_Demo].[dbo].[flights]&quot;,&quot; Select top 100 [2012],[2013],[2014],[2015] From [Cab_Demo].[dbo].[flights] PIVOT ( count(flight) FOR year in ([2012],[2013],[2014],[2015]) ) as pvt&quot;) dbconnectworkload &lt;- function() { con &lt;- dbConnect(odbc::odbc(),Driver= myDriver,Server = myServer ,Database = myDatabase,Trusted_Connection=&#39;yes&#39;) dbGetQuery(con,queries[1]) dbDisconnect(con) con &lt;- dbConnect(odbc::odbc(),Driver= myDriver,Server = myServer ,Database =myDatabase,Trusted_Connection=&#39;yes&#39;) dbGetQuery(con,queries[2]) dbDisconnect(con) con &lt;- dbConnect(odbc::odbc(),Driver= myDriver,Server = myServer ,Database =myDatabase,Trusted_Connection=&#39;yes&#39;) dbGetQuery(con,queries[3]) dbDisconnect(con) } poolcon &lt;- dbPool(odbc::odbc(),Driver= myDriver,Server = myServer ,Database = myDatabase,Trusted_Connection=&#39;yes&#39;) dbpoolworkload &lt;- function() { dbGetQuery(poolcon,queries[1]) dbGetQuery(poolcon,queries[2]) dbGetQuery(poolcon,queries[3]) } results &lt;- microbenchmark::microbenchmark(dbconnectworkload() ,dbpoolworkload(),times = 5) poolClose(poolcon) results The pooled function connection appears to be 10 times faster. Profvis shows that most of the time spent in dbconnectworkload is on opening connections. library(profvis) profvis({dbconnectworkload ()}) "],
["connection-summary.html", "2.5 Connection Summary", " 2.5 Connection Summary Database interaction starts with a connection. I mentioned a few common connection problems and how to troubleshoot them. Once I have a connection, then I begin testing queries. The DBI function dbGetQuery takes two arguments - 1) the connection 2) a query string. Finally, I mentioned that it’s good to get in the habit of closing connections or use the pool package. "],
["performance.html", "Chapter 3 Performance ", " Chapter 3 Performance "],
["pitfalls-of-abstraction.html", "3.1 Pitfalls of Abstraction", " 3.1 Pitfalls of Abstraction Virtue is the golden mean between two vices, the one of excess and the other of deficiency. -Aristotle What Aristotle says about virtue also applies to abstraction. If we had no abstraction life would be more challenging. I don’t need to know the internals of power steering to use a car. The wheel becomes an interface to the complexities. At the other extreme, a lack of fundamental knowledge causes problems. The fact that combustion engines require gasoline is an implementation detail. All drivers must understand this level of detail or they will quickly become hitchikers. R offers no shortage of abstraction layers and packages. The DBI package provides a layer of abstraction between the R user and the underlying database system. Many R users have no need or desire to understand the internals of a RDBMS. However, if they understand the basics of databases then they can deliver a more robust solution. The R function dbCreateTable() from DBI allows the user to create a SQL table without defining column data types. It’s tedious to look at each column and figure out the most appropriate data type but failure to do so can lead to future performance problems. For example, suppose we use dbCreateTable() with the Yellow Cab data file. url &lt;- &quot;https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2018-01.csv&quot; download.file(url,&quot;D:/Cab_Data/yellow_tripdata_2018-01.csv&quot;) trips_fs&lt;- read_csv(&#39;D:/Cab_Data/yellow_tripdata_2018-01.csv&#39;) dbCreateTable(con,&#39;yellow_trip_summary_model&#39;,trips_fs) First the dbCreateTable function generates a CREATE TABLE SQL statement. Then the statement is executed against the database specified in connection argument. A single line of R code replaces several lines of SQL code. CREATE TABLE yellow_trip_summary( [VendorID] [float] NULL, [tpep_pickup_datetime] [datetime] NULL, [tpep_dropoff_datetime] [datetime] NULL, [passenger_count] [float] NULL, [trip_distance] [float] NULL, [RatecodeID] [float] NULL, [store_and_fwd_flag] [varchar](255) NULL, [PULocationID] [float] NULL, [DOLocationID] [float] NULL, [payment_type] [float] NULL, [fare_amount] [float] NULL, [extra] [float] NULL, [mta_tax] [float] NULL, [tip_amount] [float] NULL, [tolls_amount] [float] NULL, [improvement_surcharge] [float] NULL, [total_amount] [float] NULL, [Hour_Range] [varchar](10) NULL, [Day] [char](3) NULL ) The generated code might meet the requirements but it has some flaws. First, is the FLOAT data type appropriate for every numeric data type? Float expresses approximate numeric values with a default storage size of eight bytes. Being able to express a value as floating point data with eight bytes of storage is unessicary for several of the columns. For example, the payment_type column could be defined as TINYINT because only five classes of payment types exist. SELECT payment_type,count(1) FROM [Cab_Demo].[dbo].[yellow_trip_summary_partitioned] group by payment_type As long as the number of payment type classes stays below 256, TINYINT will work. Using TINYINT, with a storage size of one byte would save space and could help prevent odd codes from entering the database. Should users be able to enter a payment code of 4.2? They technical could with a float data type. When performance or accuracy matters then developers should specify the data types. I created another table with smallest possible data type for each column. At 100 million rows, this table design requires 44% less disk space compared to the first table. CREATE TABLE [dbo].[yellow_trip_summary]( [VendorID] [tinyint] NULL, [tpep_pickup_datetime] [datetime] NULL, [tpep_dropoff_datetime] [datetime] NULL, [passenger_count] [tinyint] NULL, [trip_distance] [smallint] NULL, [RatecodeID] [tinyint] NULL, [store_and_fwd_flag] [char](1) NULL, [PULocationID] [smallint] NULL, [DOLocationID] [smallint] NULL, [payment_type] [tinyint] NULL, [fare_amount] [decimal](8, 2) NULL, [extra] [decimal](8, 2) NULL, [mta_tax] [decimal](8, 2) NULL, [tip_amount] [decimal](8, 2) NULL, [tolls_amount] [decimal](8, 2) NULL, [improvement_surcharge] [decimal](8, 2) NULL, [total_amount] [decimal](8, 2) NULL, [Hour_Range] [varchar](10) NULL, [Day] [char](3) NULL ) The size on disk for the first table is 16.1 gb and the second table is 8.9 gb. A difference of 7.2 GB might not seem like a big deal. After all, disk space is relatively cheap. But disk shouldn’t be the only consideration for design. The 7.2 GB now takes up room in memory. Memory Network Backups Indexes Replication "],
["indexing.html", "3.2 Indexing", " 3.2 Indexing "],
["host-resources.html", "3.3 Host Resources", " 3.3 Host Resources "],
["security.html", "Chapter 4 Security ", " Chapter 4 Security "],
["injection-attacks-childs-play.html", "4.1 Injection Attacks = Child’s Play", " 4.1 Injection Attacks = Child’s Play Injection based attacks have been the number one security risk to Web-apps since 2010. Why is injection at the top? For one, Hackers discover vulnerable sites with little effort. Tools like Havij and Shodan make injection attacks child’s play. The potential impact from injection-based attacks, especially SQL injection, is severe. SQL injection vulnerabilities allow hackers to circumvent security controls and run arbitrary scripts against the database. These scripts might steal data, destroy data, create a backdoor or all the above. Despite the awareness of injection risks, organizations have trouble eliminating the threat. The news article featured in the GIF below were all written in the last two years. They are a few examples of SQL injection that I found interesting. Large organizations like Cisco, Instagram, and Texas.Gov discovered injection vulnerabilities since 2018. MySQL and PostgreSQL write source code for database systems, and even they are not immune. "],
["breaking-down-a-shiny-app.html", "4.2 Breaking Down a Shiny App", " 4.2 Breaking Down a Shiny App I built a simple shiny app to illustrate how injection works. The app takes an email address and job title as inputs and saves them to a SQL Server database. Users can also update and delete existing records. The app persists user input in one table named dbo.Persons. The following SQL creates dbo.Persons and then inserts one row. The last statement selects all the rows. SET NOCOUNT ON; DROP TABLE IF EXISTS dbo.Persons; CREATE TABLE dbo.Persons ( email Varchar(100) PRIMARY KEY, jobtitle Varchar(100) ); INSERT INTO dbo.Persons VALUES (&#39;q1724449@nwytg.net&#39;,&#39;Analyst&#39;); SELECT email, jobtitle FROM dbo.Persons; The shiny UI controls provide input to the following queries. R combines the user input and query code. -- Select all rows from the dbo.Persons table SELECT * FROM dbo.Persons --Get the jobtitle where the email address matches the user-provided email SELECT jobtitle FROM dbo.Persons WHERE email = &#39;User Input&#39; --Update the Email and job title where the email address matches the user-provided email UPDATE dbo.Persons SET Email = &#39;User Input&#39;,jobtitle= &#39;User Input&#39; WHERE email =&#39;User Input&#39;) --Delete a row where the email matches user input DELETE FROM dbo.Persons WHERE Email = &#39;User Input&#39; --add a new row to the dbo.Persons table based on user-provided email and jobtitle INSERT INTO dbo.Persons(email,jobtitle) VALUES (&#39;User Input&#39;,&#39;User Input&#39;) SELECT, UPDATE, DELETE, and INSERT are the fundamental operations of data modification language (DML). My sample app only executes DML code. The other types of query code are data control language (DCL) and data definition language (DDL). I have not seen many apps use DCL and DDL, but there’re times when it’s useful. The CREATE TABLE query above is an example of DDL. The code below concatenates the user input with query code and executes the statement. dbGetQuery(myPool, paste0(&quot;Select jobtitle From dbo.Persons Where email =&#39;&quot;,input$titled,&quot;&#39;&quot;)) dbGetQuery(myPool, paste0(&quot;UPDATE dbo.Persons SET Email = &#39;&quot;,input$emailupdate,&quot;&#39;,jobtitle= &#39;&quot;,input$titleupdate,&quot;&#39; Where email =&#39;&quot;,input$titled,&quot;&#39;&quot;)) dbGetQuery(myPool, paste0(&quot;DELETE From dbo.Persons WHERE Email = &#39;&quot;,input$titled,&quot;&#39;&quot;)) dbGetQuery(myPool ,paste0(&quot;Insert into dbo.Persons values (&#39;&quot;,input$email,&quot;&#39;,&#39;&quot;,input$title,&quot;&#39;)&quot;)) The code is vulnerable to SQL injection. Nothing is stopping a user from passing a SQL script to either one of the inputs. The GIF below first shows how a user a suppose to interact with the app. Then it shows how a hacker can pass a malicious script through the email input field. The string executed against the database is two separate SQL commands. The second command truncates the Persons table. In a real-world production system, this might be data loss or application downtime. email &lt;- &quot;&#39;&#39;,&#39;&#39;) TRUNCATE TABLE dbo.Persons --&quot; title &lt;- &quot;Analyst&quot; paste0(&quot;Insert into dbo.Persons values (&#39;&quot;,email,&quot;&#39;,&#39;&quot;,title,&quot;&#39;)&quot;) "],
["defending-against-injection.html", "4.3 Defending Against Injection", " 4.3 Defending Against Injection 4.3.1 Paramertization and String Escaping The app mixes trusted data with untrusted data. Trusted data is the query code, and untrusted data is user input. If untrusted data mixes with trusted data, then query code becomes changeable at run time. I can start to separate the trusted and untrusted data through parameterized queries. Instead of passing the user input variables to the query string, I store them in parameters. Then I reference the parameters instead of the user variables. query &lt;- sqlInterpolate(con,&quot;INSERT INTO dbo.Persons VALUES (?email,?title)&quot;,input$email,input$title)) dbGetQuery(myPool, query) The sqlInterpolate function helps isolate the user input from the query string. Also, sqlinterpolate escapes single tick marks making it difficult to execute ad-hoc scripts. The injection attack fails this time because the code handles input as one continuous string. 4.3.2 Whitelist input The app should only allow valid characters as input. If a user enters an email with spaces, then the app should reject it. I implemented an email whitelist by comparing the input with a Regex pattern. emailwhitelist &lt;- &quot;^[[:alnum:].-_]+@[[:alnum:].-]+$&quot; if(!is.na(str_match(input$email, emailwhitelist))){ query &lt;- sqlInterpolate(con, &quot;INSERT INTO dbo.Persons VALUES(?email,?title)&quot;,input$email,input$title)) dbGetQuery(myPool, query) } else {stop(&quot;Not a valid email.&quot;)} Developers should whitelist with caution. Using a restrictive character set could block legitimate input. The Regex pattern above blocks email addressed with a single quote. Are quotes possible in emails? If they aren’t allowed will that change in the future? It’s possible. A whitelist requires a balance between security and usability. 4.3.3 Server Side Defense The database user account should have minimal permissions. I would not have been able to truncate the table in the example above had I only had permission to SELECT and INSERT. Interfaces simplify permissions. Instead of granting permissions on tables I can grant permissions on the interface. Stored procedures make great interfaces. Developers can grant permissions on stored procedures without granting access to tables. Thus DB all interactions occur in the manner defined by the stored procedure. I can wrap the INSERT statement into a stored procedure. The shinybuilder_app user cannot run an INSERT statement outside of the stored procedure. Use Cab_Demo GO DROP PROCEDURE IF EXISTS dbo.uspInsertEmail; GO CREATE PROCEDURE dbo.uspInsertEmail @email Varchar(100), @title Varchar(100) AS INSERT INTO dbo.Persons VALUES (@email,@title) GO GRANT EXECUTE ON dbo.uspInsertEmail TO shinybuilder_app Now the app calls the stored procedure instead of ad-hoc SQL. query &lt;- sqlInterpolate(con ,&quot;EXECUTE dbo.uspInsertEmail ?email,?title&quot;,input$email,input$title)) dbGetQuery(myPool, query) 4.3.4 Other defense layers A few lines of defense exist outside of the app and database server. An intrusion detection system (IDS) uses signatures to detect potential attacks. Some IDS also provide real-time alerting features. Vendor provided patches often contain security fixes. System admins or developers should apply security fixes as soon as possible. 4.3.5 Defense in Depth Even big firms struggle to manage injection risks, and no code is 100% secure. However, parametrization and whitelists are good first lines of defense. "],
["final-words.html", "Chapter 5 Final Words", " Chapter 5 Final Words We have finished a nice book. "],
["references.html", "References", " References "]
]
